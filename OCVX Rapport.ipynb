{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ocvx\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1: Méthode de Newton\n",
    "\n",
    "### Problèmes d'optimisation convexe sans contraintes\n",
    "\n",
    "Avant de commencer à étudier la méthode de Newton, générons des problèmes d'optimisation convexe sans contraintes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unconstrained = ocvx.getUnconstrainedProblems()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode de Newton est une méthode permettant de résoudre des problèmes d'optimisation convexe. Sa principale différence par rapport à la descente de gradient est l'utilisation de la héssienne de la fonction objectif. Cela fait de la méthode de Newton une méthode de second ordre. Son fonctionnement ayant déjà été expliqué en cours, nous ne la décririons pas dans cette partie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(unconstrained.shape[0]):\n",
    "    print(\"Problem\", i, \":\", unconstrained.iloc[i][\"name\"], \"with constant\")\n",
    "    P = unconstrained.iloc[i][\"probleme\"]\n",
    "    if P.f.dim == 1:\n",
    "        x0 = np.array([10])\n",
    "    else:\n",
    "        x0 = np.array([15, 20])\n",
    "    meth = ocvx.Newton(P, ocvx.constant)\n",
    "    print(\"x* =\", meth(x0))\n",
    "    print(\"Nombre d'itération:\", meth.save.shape[0])\n",
    "    meth.plot()\n",
    "    \n",
    "    print(\"Problem\", i, \":\", unconstrained.iloc[i][\"name\"], \"with backtracking\")\n",
    "    meth = ocvx.Newton(P, ocvx.backtracking)\n",
    "    print(\"x* =\", meth(x0))\n",
    "    print(\"Nombre d'itération:\", meth.save.shape[0])\n",
    "    meth.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur les graphiques ci-dessus, les points rouges représentent les points à chaque itération de l'algorithme. Pour les fonction en deux dimensions, nous avons choisi de les représenter sous la forme de lignes de niveau. Plus la couleur de la courbe est sombre, plus la valeur de la fonction objectif est petite.\n",
    "\n",
    "La première observation que l'on peut faire est que la méthode de Newton avec une valeur de pas constant (dans notre cas fixé empiriquement à une valeur de 0.01) est beaucoup plus lente qu'avec une valeur de pas calculée à chaque itération de notre algorithme à l'aide du **backtracking**.\n",
    "\n",
    "Comparons maintenant la descente de gradient (classique) à la méthode de Newton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(unconstrained.shape[0]):\n",
    "    print(\"Problem\", i, \":\", unconstrained.iloc[i][\"name\"], \"with constant\")\n",
    "    P = unconstrained.iloc[i][\"probleme\"]\n",
    "    if P.f.dim == 1:\n",
    "        x0 = np.array([10])\n",
    "    else:\n",
    "        x0 = np.array([15, 20])\n",
    "    meth = ocvx.GradientDescent(P, ocvx.constant)\n",
    "    print(\"x* =\", meth(x0))\n",
    "    print(\"Nombre d'itération:\", meth.save.shape[0])\n",
    "    meth.plot()\n",
    "    \n",
    "    print(\"Problem\", i, \":\", unconstrained.iloc[i][\"name\"], \"with backtracking\")\n",
    "    meth = ocvx.GradientDescent(P, ocvx.backtracking)\n",
    "    print(\"x* =\", meth(x0))\n",
    "    print(\"Nombre d'itération:\", meth.save.shape[0])\n",
    "    meth.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode de Newton et la descente de gradient présente plusieurs différences plusieurs différences. Premièrement, la descente de gradient avec un pas constant prend moins d'itérations pour minimiser la fonction objectif. Cela est surement dû au fait que la descente de gradient est une méthode de premier ordre qui dépend du gradient alors que la méthode de Newton dépend de la Hessienne.\n",
    "\n",
    "Ensuite, on observe que la descente de gradient utilisant le backtracking pour le calcul du pas va parfois trop loin et donc nécéssite de retourner en arrière pour minimiser la fonction objectif. On a donc plus d'itération pour la descente de gradient que pour la méthode de Newton en utilisant le backtracking.\n",
    "\n",
    "### Problèmes d'optimisation convexe avec contraintes d'égalité\n",
    "\n",
    "Un problème d'optimisation convexe avec des contraintes d'égalité peut se poser sous la forme\n",
    "\n",
    "$$\n",
    "\\underset{x}{\\text{min}} f(x)\\\\\n",
    "Ax = b\n",
    "$$\n",
    "\n",
    "avec $f : \\mathbb{R}^n \\to \\mathbb{R}$ et $\\text{rang}(A) < n$\n",
    "\n",
    "Le but de cette partie est de comparer des méthodes de résolutions de problèmes d'optimisation convexe avec contraintes d'égalité.\n",
    "\n",
    "Un première approche est d'éliminer les contraintes d'égalités. Pour éliminer les contraintes d'égalité, on va transformer notre problème d'optimisation avec contraintes d'égalité en un système d'optimisation convexe sans contraintes.\n",
    "\n",
    "Soit $F$ un matrice tel que $AF = 0$ et $x_0$ un point initiale de notre problème tel que $Ax_0 = b$. On va donc chercher à minimiser une variable $z$ dans un problème de la forme :\n",
    "$$\n",
    "\\underset{z}{\\text{min}} f(Fz + x_0)\n",
    "$$\n",
    "Dès que ce problème est minimisé, le point optimal du problème initial sera retrouvé en effectuant l'opération suivante :\n",
    "$$\n",
    "x^{*} = Fz^{*} + x_0\n",
    "$$\n",
    "\n",
    "Montrons maintenant les résultats de la résolution d'un problème d'optimisation avec contraintes d'égalité en utilisant cette première méthode.\n",
    "\n",
    "Pour commencer, générons des problèmes d'optimisation convexe avec contraintes d'égalité :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constrained = ocvx.getConstrainedProblems()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, testons notre descente de gradient après élimination des contraintes d'égalité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(constrained.shape[0]):\n",
    "    P = constrained.loc[i][\"probleme\"]\n",
    "    x0 = constrained.loc[i][\"x0\"]\n",
    "    name = constrained.loc[i][\"name\"]\n",
    "    \n",
    "    print(\"Descente de gradient du problème\", name, \"avec contraintes d'égalité\")\n",
    "    print(\"Avec pas constant\")\n",
    "    meth = ocvx.EQGradient(P, ocvx.constant)\n",
    "    print(\"x* =\", meth(x0))\n",
    "    print(\"Nombre d'iteration =\", len(meth.save))\n",
    "    meth.plot()\n",
    "    \n",
    "    print(\"Avec backtracking\")\n",
    "    meth = ocvx.EQGradient(P, ocvx.eqgrad_backtracking)\n",
    "    print(\"x* =\", meth(x0))\n",
    "    print(\"Nombre d'iteration =\", len(meth.save))\n",
    "    meth.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons choisi de ne montrer que des problèmes de dimensions 2, la résolution d'un problème d'optimisation convexe avec contraintes d'égalité de dimension 1 n'étant pas possible et les problèmes d'optimisation convexe de dimension supérieur à 2 étant plus difficile à visualiser.\n",
    "\n",
    "On remarque que la résolution de notre problème de minimisation respecte bien les contraintes $Ax = b$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2: Régularisation de problèmes mal posés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préambule\n",
    "\n",
    "### Un problème mal posé ?\n",
    "\n",
    "Qu'est-ce-qu'un problème mal posé ? Pour commencer, nous allons définir qu'est ce qu'un problème bien posé. Un problème ($P$) bien posé dit respecter les 3 conditions suivantes:\n",
    "* Une solution au problème $P$ existe\n",
    "* La solution est unique\n",
    "* La solution dépend continuellement de la donnée\n",
    "\n",
    "Un problème mal posé est un problème ($P$) qui ne respecte pas une des conditions situées au dessus. Il est donc difficile de trouver une solution aux problèmes mal posés avec les méthodes vues auparavant. Pour trouver une solution optimale à ce type de problème nous allons utiliser la méthode analytique des moindres carrés.\n",
    "Nous utiliserons aussi les méthodes de régularisation telles que LASSO ou Tikhonov."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La méthode analytique des moindres carrées\n",
    "\n",
    "#### Principe\n",
    "\n",
    "Le but de la résolution de la méthode analytique des moindres de carrés est de pouvoir trouver une solution permettant de trouver une relation entre des groupes différents en ajoutant de l'information dans ces données.[BV04]\n",
    "\n",
    "Plus en détails, on recherche le vecteur $y \\in \\mathbb{R}^N$ qui contient les éléments {$y_1, y_2, ..., y_n$} où $y_i \\in R$. Le vecteur $y$ résulte d'une corrélation des données de la matrice $X$ qui est une matrice $N \\times P$ où $P$ représente le nombre de paramètres des éléments $x$. Nous allons en déduire $y$ à l'aide de la formule suivante:\n",
    "$$\n",
    "y = X\\beta + \\epsilon\n",
    "$$\n",
    "\n",
    "où\n",
    "* $\\beta$ est vecteur de paramètre qui rajoute l'information dans les données X.\n",
    "* $\\epsilon$ qui représente les résidus (différence entre le point et la droite $y$) aussi appeler erreur de prédiction.\n",
    "\n",
    "On peut calculer la SSE (Sum of Squared Errors) qui représente la somme de tous les résidus.\n",
    "\n",
    "$$\n",
    "SSE(\\beta) = \\sum_{i}^{N}((y_i - x_i^T\\beta)^2)\\\\\n",
    "SSE(\\beta) = (y - X\\beta)^T(y - X\\beta)\\\\\n",
    "SSE(\\beta) = ||y - X\\beta||^2_2\n",
    "$$\n",
    "\n",
    "La $SSE$ va nous permettre d'appliquer des pénalités à nos données afin de trouver la solution optimale à notre problème.\n",
    "\n",
    "Cette méthode est utiliser dans le domaine du machine learning avec notamment $\\beta$ telle que les régresseurs et $\\epsilon$ les erreurs de prédiction de $y$. Cette méthode va permettre de trouver la meilleure solution en ajoutant une fonction de pénalité sur le $SSE$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les méthodes de régularisation\n",
    "\n",
    "### Préambule\n",
    "\n",
    "Comme vu précédemment, la méthode des moindres carrés permet de trouver une corrélation entre des ensembles différents. Nous avons vu la notion de $SSE$ comme étant la somme des résidus. Afin de pouvoir trouver la séparation optimale, il faut trouver un moyen de minimiser la $SSE$. Nous allons utiliser des méthodes de régularisation et de pénalité que nous allons appliquer sur la $SSE$. Au cours de cette question, nous allons présenter les méthodes de régularisation Tikhonov et de LASSO.\n",
    "\n",
    "On rappelle la $SSE$:\n",
    "\n",
    "$$\n",
    "SSE(\\beta) = ||y - X\\beta||^2_2\n",
    "$$\n",
    "\n",
    "où\n",
    "* $\\beta$ est notre ensemble\n",
    "* $y$ notre fonction objective\n",
    "* $X$ les points\n",
    "\n",
    "On définit une pénalité dans le domaine du machine learning (ML) par la minisation de la formule suivante:\n",
    "\n",
    "$$\n",
    "arg min \\ Pen(\\beta) = \\mathcal{L}(\\beta) + \\lambda \\Omega(x)\n",
    "$$\n",
    "\n",
    "où\n",
    "* $\\mathcal{L}(\\beta)$ est la fonction de regression (fonction perte en ML)\n",
    "* $\\lambda$ est le paramètre de régularisation\n",
    "* $\\Omega(\\beta)$ est la fonction de pénalité\n",
    "\n",
    "Les deux méthodes présentent en dessous utilisent deux fonctions de pénalité différentes avec laquelle nous pourrons trouver le vecteur $\\beta$ le plus optimal possible à notre problème.\n",
    "\n",
    "### Les méthodes\n",
    "#### Tikhonov\n",
    "\n",
    "Tikhonov (de son vrai non Andreï Nikolaïevitch Tikhonov) est un mathématicien russe. Il est connu pour avoir prouvé la régularisation qui porte son nom. Le but de cette régularisation est d'appliquer une régularisation $\\mathcal{L}_2$ comme fonction de pénalité. Cette régularisation s'appelle aussi Ridge[TiK43].\n",
    "\n",
    "$$\n",
    "Ridge(\\beta) = ||y-X\\beta||^{2}_{2} - \\lambda ||\\beta||^2_2\n",
    "$$\n",
    "\n",
    "Afin de pouvoir trouver le $\\beta$ minimal, il suffit de résoudre:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial{Ridge}}{\\partial{\\beta}} = 0\n",
    "$$\n",
    "\n",
    "Ce qui nous donne:\n",
    "\n",
    "$$\n",
    "\\iff\\frac{\\partial{}}{\\partial{\\beta}} ((y - X\\beta)^T(y - X\\beta) + \\lambda\\beta^T\\beta) = 0\\\\\n",
    "\\iff\\frac{\\partial{}}{\\partial{\\beta}} (y^Ty - 2\\beta^TX^Ty + \\beta^TX^X\\beta + \\lambda\\beta^T\\beta) = 0\\\\\n",
    "\\iff -2X^Ty + 2X^TX\\beta + 2\\lambda\\beta = 0\\\\\n",
    "\\iff -X^Ty + (X^TX + \\lambda)\\beta = 0\\\\\n",
    "\\iff \\beta = \\frac{X^Ty}{X^TX + \\lambda}\n",
    "$$\n",
    "\n",
    "#### LASSO\n",
    "\n",
    "La méthode régularisation de LASSO permet d'appliquer une pénalité $||\\beta||_1$ à la méthode de régularisation ce qui donne:\n",
    "\n",
    "\n",
    "$$\n",
    "LASSO(\\beta) =||y-X\\beta||^{2}_{2} + \\lambda||\\beta||_1\n",
    "$$\n",
    "\n",
    "La fonction de pénalité est une régularisation $\\mathcal{L}_1$[Tib96].\n",
    "\n",
    "L'avantage d'utiliser la régularisation de LASSO est de l'utiliser dans le cas où $N < P$. La régularisation $\\mathcal{L}_1$ s'adapte mieux que la régularisation $\\mathcal{L}_2$ sur ce type de données. Hors il n'est pas adapté dans le cadre de fortes corrélations entre les variables ou si $P$ est très grand par rapport à $n$.\n",
    "\n",
    "Nous pouvons faire utiliser les deux régularisation en même temps en utilisant Elsatic NET[Hui03]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réferences\n",
    "\n",
    "[BV04] **Convex Optimization.**\n",
    "        Stephen Boyd and Lieven Vandenberghe.\n",
    "        *Cambridge University Press, New York, NY, USA* 2004.\n",
    "\n",
    "[TiK43] **On the stability of inverse problems**\n",
    "    A. N. Tikhonov\n",
    "    *Doklady Akademii Nauk SSSR* vol. 39, no. 5, pp. 195–198, 1943.\n",
    "\n",
    "[Tib96] **Regression shrinkage and selectionvia the lasso.**\n",
    "        R. Tibshirani.\n",
    "        *Journal ofthe Royal Statistical Society* Series B, 58(1):267–288, 1996.\n",
    "        \n",
    "[Hui03] **Regularization and Variable Selection via theElastic Net**\n",
    "    Hui Zou and Trevor Hastie\n",
    "    *Department of Statistics, Stanford University*, 2003"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partie implémentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant implémenter la méthodes des moindres carrés avec les deux types de régularisation vues au dessus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class least_square:\n",
    "    def __init__(self, X):\n",
    "        \"\"\"Constructor of the least_square.\n",
    "           \n",
    "           Parameter\n",
    "           ---------\n",
    "               X: A numpy array\n",
    "                   Represents a matrix N x P which\n",
    "                   N is the length of element and P number of features\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.beta = np.zeros(X.shape[1])\n",
    "        self.eps = np.random.randn(X.shape[0])\n",
    "        self.y = self.X.dot(self.beta) + self.eps \n",
    "        for i in range(self.y.shape[0]):\n",
    "            r = (self.y[i] - self.beta.dot(self.X[i,:]))\n",
    "            self.eps[i] = r**2\n",
    "        \n",
    "        self.SSE = []\n",
    "        self.max_iter = 0\n",
    "        \n",
    "       \n",
    "    def compute_SSE(self):\n",
    "        \"\"\"Compute the SSE of the model.\n",
    "           \n",
    "           Return:\n",
    "           -------\n",
    "               integer which represents the SSE of the model.\n",
    "        \"\"\"\n",
    "        return np.linalg.norm(self.y - self.X.dot(self.beta), ord=2)**2\n",
    "\n",
    "\n",
    "    def tikhonov_reg(self, alpha, y, max_iter=10):\n",
    "        \"\"\"Constructor of the least_square.\n",
    "           \n",
    "           Parameters\n",
    "           ----------\n",
    "               alpha: float\n",
    "                   Represents the regularisation paramter (lambda)\n",
    "               y: vector\n",
    "                   Reference of the matrix X\n",
    "               max_iter: int\n",
    "                   Set the maximum of iteration (default: 10)\n",
    "            Return:\n",
    "            -------\n",
    "                the prediction\n",
    "        \"\"\"\n",
    "        iteration = 0\n",
    "        self.max_iter = max_iter\n",
    "        while iteration < max_iter:\n",
    "            self.y = np.dot(self.X, self.beta)\n",
    "            self.eps = self.y - y\n",
    "            self.beta = np.linalg.inv(np.transpose(self.X).dot(self.X) + np.identity(self.X.shape[1]) * alpha).dot(np.transpose(self.X).dot(self.eps))\n",
    "            if iteration < 5 or iteration >= max_iter - 5:\n",
    "                print(\"epoch: %d/%d\" % (iteration + 1, max_iter))\n",
    "                print(\"SSE = %f\" % self.compute_SSE())\n",
    "            elif iteration == 5:\n",
    "                print()\n",
    "                print(\"...\")\n",
    "                print()\n",
    "            self.SSE.append(self.compute_SSE())\n",
    "            iteration += 1\n",
    "        return self.y\n",
    "    \n",
    "    def plot(self, y_ref):\n",
    "        \"\"\"Plot the result of regularisation.\n",
    "        \n",
    "           Parameter\n",
    "           ---------\n",
    "               y_ref: vector of float\n",
    "                   Represents the y reference of X to plot it\n",
    "        \"\"\"\n",
    "        fig = plt.figure(figsize=(21, 6))\n",
    "        ax = fig.add_subplot(121)\n",
    "        ax.set_title(\"Evolution of the SSE\")\n",
    "        plt.xlabel(\"epochs\")\n",
    "        plt.ylabel(\"SSE\")\n",
    "        ax.plot(np.arange(1,self.max_iter+1), self.SSE, c='green', label='SSE')\n",
    "        leg = ax.legend()\n",
    "        \n",
    "        ax = fig.add_subplot(122)\n",
    "        ax.set_title(\"\")\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Y\")\n",
    "        ax.scatter(self.X[:,0], y_ref, c='red', marker='o', label='y reference')\n",
    "        print(self.X.shape)\n",
    "        if self.X.shape[1] == 1:\n",
    "            ax.plot(self.X[:,0], self.y, c='green', label='y pred')\n",
    "        else:\n",
    "            ax.scatter(self.X[:,0], self.y, c='green', marker='x', label='y pred')\n",
    "        leg = ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 1   # = P (number of features)\n",
    "n_samples = 100  # = N (number of elements)\n",
    "\n",
    "\n",
    "# Create dataset\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "Y = np.random.randn(n_samples)\n",
    "\n",
    "# Create the least_square and doing a L2 regression\n",
    "l = least_square(X)\n",
    "l.tikhonov_reg(0.1, y=Y, max_iter=100)\n",
    "\n",
    "\n",
    "# plot results\n",
    "l.plot(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 3: SVC et SMO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principe\n",
    "\n",
    "Le principe des SVC est de séparer l'espace en deux sous-espaces, celui des échantillons négatifs, et celui des positifs, en aillant la séparation la plus grande possible. Les SVC sont donc assimilés à un problème d'optimisation.\n",
    "\n",
    "On pose $\\vec w$ le vecteur normal à notre hyperplan qui sépare nos échantillons positifs et négatifs. On ne connait pas encore sa longueur. On a aussi un point que l'on veut classifier, représenté par le vecteur $\\vec u$. On le projette donc sur $\\vec w$, ce qui revient donc à voir notre classification positive comme:\n",
    "\n",
    "$$\n",
    "\\vec w \\cdot \\vec u \\geqslant C\n",
    "\\iff \\vec w \\cdot \\vec u + b \\geqslant 0\n",
    "$$\n",
    "\n",
    "avec $C$ et $b$ des constantes.\n",
    "\n",
    "On pose à nouveau plusieurs contraintes:\n",
    "\n",
    "$$\n",
    "\\vec w \\cdot \\vec x_{+} + b \\geqslant 1\n",
    "$$\n",
    "$$\n",
    "\\vec w \\cdot \\vec x_{-} + b \\leqslant -1\n",
    "$$\n",
    "\n",
    "ou $\\vec x_{+}$ correspond à un échantillon positif et $\\vec x_{-}$ à un négatif.\n",
    "\n",
    "On introduit $y_{i}$ tel que $y_{i} = 1$ pour un échantillon positif et $y_{i} = -1$ pour un échantillon négatif. En multipliant les équations précédentes par $y_{i}$, on obtient:\n",
    "\n",
    "$$\n",
    "y_{i}(\\vec w \\cdot \\vec x_{i} + b) \\geqslant 1\n",
    "$$\n",
    "$$\n",
    "\\iff y_{i}(\\vec w \\cdot \\vec x_{i} + b) -1 \\geqslant 0\n",
    "$$\n",
    "\n",
    "Et l'on peut dire des échantillons qui tombent dans la séparation, que:\n",
    "\n",
    "$$\n",
    "y_{i}(\\vec w \\cdot \\vec x_{i} + b) -1 = 0\n",
    "$$\n",
    "\n",
    "Pour obtenir la largeur de la séparation, il suffit de soustraire un échantillon négatif à un positif et de le multiplier par un vecteur unitair normal à notre hyperplan, comme suit:\n",
    "\n",
    "$$\n",
    "width = (\\vec x_{+} - \\vec x_{-})  \\cdot \\frac{\\vec w}{||\\vec w||} = \\frac{2}{||\\vec w||}\n",
    "$$\n",
    "\n",
    "Puisqu'on cherche à avoir la plus grande séparation inter-classe, on cherche donc à maximiser $\\frac{2}{||\\vec w||}$, ce qui revient à chercher à minimiser $||\\vec w||$, ou, pour plus de convénience mathématique, à minimiser $\\frac{1}{2}||\\vec w||^2$ sujet à $y_{i}(\\vec w \\cdot \\vec x_{i} + b) -1 \\geqslant 0$.\n",
    "\n",
    "En passant par le Lagrangien, on obtient:\n",
    "\n",
    "$$L = \\frac{1}{2}||\\vec w||^2 - \\sum \\alpha_{i} [y_{i}(\\vec w \\cdot \\vec x_{i} + b) - 1]$$\n",
    "\n",
    "ou $\\alpha_{i}$ sont les coefficient multiplicateur du Langrangien. On dérive partiellement par $\\vec w$ et $b$.\n",
    "\n",
    "$$\\frac{\\partial{L}}{\\partial{w}} = 0 \\iff \\vec w - \\sum \\alpha_{i} y_{i} \\vec x_{i} = 0$$\n",
    "$$\\iff \\vec w = \\sum \\alpha_{i} y_{i} \\vec x_{i}$$\n",
    "$$\\frac{\\partial{L}}{\\partial{b}} = 0 \\iff - \\sum \\alpha_{i} y_{i}= 0$$\n",
    "$$\\iff b = \\sum \\alpha_{i} y_{i}$$\n",
    "\n",
    "C'est grâce à ces égalités qu'on va, entre autre, pouvoir implémenter la SMO, ou Sequential Minimal Optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implémentation de la SMO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principe\n",
    "\n",
    "La SMO est un algorithme qui permet de résoudre rapidement des problèmes d'optimisation de type SVC QP (quadratic programming) de manière analytique. Cet algorithme se base sur le théorème de Osuna qui assure la convergence en cas de subdivision de problèmes QP en sous problèmes QP.\n",
    "\n",
    "A chaque étape, on choisit de résoudre le problème d'optimisation le plus petit possible. Celui-ci implique deux coefficients multiplicateurs de Lagrange, $\\alpha_{1}$ et $\\alpha_{2}$. A chaque étape, ils sont optimisés conjointement pendant que tous les autres coefficients sont conservés identiques, et ainsi de suite jusqu'à convergence. Le choix des coefficients est fait à chaque étape grâce à une heuristique, le but étant de choisir au moins un coefficient ne respectant pas les condition du KKT. Si au moins un des deux coefficients utilisé respecte cette condition, alors le problème est garantit de diminuer, via le théorème de Osuna.\n",
    "\n",
    "L'implémentation suivante est une version simplifiée de la SMO, avec un choix de coefficients aléatoire.\n",
    "\n",
    "_[sources: http://cs229.stanford.edu/materials/smo.pdf et https://www.microsoft.com/en-us/research/publication/sequential-minimal-optimization-a-fast-algorithm-for-training-support-vector-machines/]_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMO:\n",
    "    def __init__(self, kernel=None, max_iter=10000, epsilon=0.001, C=1.0):\n",
    "        if (kernel == None):\n",
    "            self.kernel = lambda x1, x2 : np.dot(x1, x2.T)\n",
    "        else:\n",
    "            self.kernel = kernel\n",
    "        self.epsilon = epsilon\n",
    "        self.C = C\n",
    "        self.max_iter = max_iter\n",
    "        self.b = None\n",
    "        self.w = None\n",
    "    \n",
    "    '''\n",
    "    the function that predict the class of an sample thanks to the normal vector w and b\n",
    "    '''\n",
    "    def h(self, X):\n",
    "        return np.sign(np.dot(self.w, X.T) - self.b).astype(int)\n",
    "    \n",
    "    '''\n",
    "    the function that computes the w vector thanks to Lagrange multipliers alpha\n",
    "    '''\n",
    "    def compute_w(self, alphas, X, y):\n",
    "        w = 0\n",
    "        for i in range(X.shape[0]):\n",
    "            w += alphas[i] * y[i] * X[i,:]\n",
    "        self.w = w\n",
    "    \n",
    "    def randexclusif(self, mn, mx, excl):\n",
    "        res = random.randint(mn, mx)\n",
    "        while (res == excl):\n",
    "            res = random.randint(mn, mx)\n",
    "        return res\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.b = 0\n",
    "        size = (X.shape[0])\n",
    "        alphas = np.zeros((size))\n",
    "        for count in range(self.max_iter):\n",
    "            prev_alphas = np.copy(alphas)\n",
    "            for i in range(size):\n",
    "                y1 = y[i]\n",
    "                x1 = X[i, :]\n",
    "                alpha1 = alphas[i]\n",
    "                \n",
    "                self.compute_w(alphas, X, y)\n",
    "                Ei = self.h(x1) - y1\n",
    "                if ((Ei*y1 < -self.epsilon and alpha1 < self.C) or (Ei*y1 > self.epsilon and alpha1 > 0)):\n",
    "                    #selection of j != i for a simplified SMO method\n",
    "                    j = self.randexclusif(0, size - 1, i)\n",
    "                    y2 = y[j]\n",
    "                    x2 = X[j, :]\n",
    "                    alpha2 = alphas[j]\n",
    "                    \n",
    "                    Ej = self.h(x2) - y2\n",
    "                    \n",
    "                    if (y1 == y2):\n",
    "                        L = max(0, alpha2 + alpha1 - self.C)\n",
    "                        H = min(self.C, alpha2 + alpha1)\n",
    "                    else:\n",
    "                        L = max(0, alpha2 - alpha1)\n",
    "                        H = min(self.C, self.C + alpha2 - alpha1)\n",
    "                    \n",
    "                    if (L == H):\n",
    "                        continue\n",
    "                    \n",
    "                    nu = self.kernel(x1, x1) + self.kernel(x2, x2) - 2 * self.kernel(x1, x2)\n",
    "                    \n",
    "                    if (nu < 0):\n",
    "                        continue\n",
    "                \n",
    "                    a2 = alpha2 + float(y2 * (Ei - Ej)) / nu\n",
    "                    if (a2 > H):\n",
    "                        a2 = H\n",
    "                    elif (a2 < L):\n",
    "                        a2 = L\n",
    "                    alphas[j] = a2\n",
    "                    \n",
    "                    if (abs(a2 - alpha2) < self.epsilon):\n",
    "                        continue\n",
    "                    \n",
    "                    alphas[i] = alpha1 + y1 * y2 * (alpha2 - a2)\n",
    "                    b1 = Ei + y1 * (alphas[i] - alpha1) * self.kernel(x1, x1) + y2 * (a2 - alpha2) * self.kernel(x1, x2) + self.b\n",
    "                    b2 = Ej + y1 * (alphas[i] - alpha1) * self.kernel(x1, x2) + y2 * (a2 - alpha2) * self.kernel(x2, x2) + self.b\n",
    "                    \n",
    "                    if (alphas[i] > 0 and alphas[i] < self.C):\n",
    "                        self.b = b1\n",
    "                    elif (a2 > 0 and a2 < self.C):\n",
    "                        self.b = b2\n",
    "                    else:\n",
    "                        self.b = (b1 + b2) / 2\n",
    "            diff = np.linalg.norm(alphas - prev_alphas)\n",
    "            if diff < self.epsilon:\n",
    "                break\n",
    "        self.compute_w(alphas, X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.h(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions de comparaisons avec un SVC linéaire classique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_problem(size, percent=0.2, linear=True):\n",
    "    if (linear):\n",
    "        separable = False\n",
    "        while not separable:\n",
    "            samples = make_classification(n_samples=size, n_features=2, n_redundant=0, n_informative=1, n_clusters_per_class=1, flip_y=-1, weights=[0.5,0.5])\n",
    "            red = samples[0][samples[1] == 0]\n",
    "            blue = samples[0][samples[1] == 1]\n",
    "            separable = any([red[:, k].max() < blue[:, k].min() or red[:, k].min() > blue[:, k].max() for k in range(2)])\n",
    "    else:\n",
    "        samples = make_classification(n_samples=size, n_features=2, n_redundant=0, n_informative=2, n_clusters_per_class=2, flip_y=-1)\n",
    "        red = samples[0][samples[1] == 0]\n",
    "        blue = samples[0][samples[1] == 1]\n",
    "    plt.plot(red[:, 0], red[:, 1], 'r.')\n",
    "    plt.plot(blue[:, 0], blue[:, 1], 'b.')\n",
    "    plt.show()\n",
    "    red = np.array([np.append(red[i], -1) for i in range(len(red))])\n",
    "    blue = np.array([np.append(blue[i], 1) for i in range(len(blue))])\n",
    "    perc = int(percent * size)\n",
    "    trainr = red[:perc]\n",
    "    testr = red[perc:]\n",
    "    trainb = blue[:perc]\n",
    "    testb = blue[perc:]\n",
    "    res = np.append(trainr, trainb, axis=0)\n",
    "    res = shuffle(res)\n",
    "    res2 = np.append(testr, testb, axis=0)\n",
    "    res2 = shuffle(res)\n",
    "    X = res[:,:2]\n",
    "    y = res[:,-1]\n",
    "    Xtest = res2[:,:2]\n",
    "    ytest = res2[:,-1]\n",
    "    return X, y, Xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def compareSVC_SMO(linear=True):\n",
    "    X, y, Xtest, ytest = generate_problem(1000, 0.2, linear)\n",
    "    Xall = np.append(X, Xtest, axis=0)\n",
    "    yall = np.append(y, ytest, axis=0)\n",
    "    minX = min(Xall[:,0])\n",
    "    maxX = max(Xall[:,0])\n",
    "    minX *= 1.2\n",
    "    maxX *= 1.2\n",
    "    model = SVC(kernel='linear', C = 1.0)\n",
    "    model.fit(X, y)\n",
    "    y_hat_svc = model.predict(X)\n",
    "    y_hattest_svc = model.predict(Xtest)\n",
    "    acc = f1_score(y, y_hat_svc)\n",
    "    acc2 = f1_score(ytest, y_hattest_svc)\n",
    "    print(\"accuracy train for SVC:\\t%.3f\" % (acc))\n",
    "    print(\"accuracy test for SVC:\\t%.3f\" % (acc2))\n",
    "    w = model.coef_[0]\n",
    "    \n",
    "    model2 = SMO()\n",
    "    model2.fit(X, y)\n",
    "    y_hat_smo = model2.predict(X)\n",
    "    y_hattest_smo = model2.predict(Xtest)\n",
    "    acc = f1_score(y, y_hat_smo)\n",
    "    acc3 = f1_score(ytest, y_hattest_smo)\n",
    "    print(\"accuracy train for SMO:\\t%.3f\" % (acc))\n",
    "    print(\"accuracy test for SMO:\\t%.3f\" % (acc3))\n",
    "    w = model2.w\n",
    "    \n",
    "    xx = np.linspace(minX,maxX)\n",
    "    fig, axs = plt.subplots(2, figsize=(20,20))\n",
    "    fig.suptitle('SVC vs SMO results', fontsize=20)\n",
    "    \n",
    "    yy = - 1 * (xx*w[0] + model.intercept_) / w[1]\n",
    "    yy1 = - 1 * (xx*w[0] + model.intercept_ - 1) / w[1]\n",
    "    yy2 = - 1 * (xx*w[0] + model.intercept_ + 1) / w[1]\n",
    "    axs[0].plot(xx, yy, 'k--', label='hyperplan')\n",
    "    axs[0].plot(xx, yy1, 'k-', label='margin')\n",
    "    axs[0].plot(xx, yy2, 'k-', label='margin')\n",
    "    axs[0].scatter(Xall[:, 0], Xall[:, 1], c = yall)\n",
    "    axs[0].set_title('SVC, accuracy: ' + str(acc2), fontsize=16)\n",
    "    axs[0].legend(loc='best', fontsize='large')\n",
    "    \n",
    "    yy3 = - 1 * (xx*w[0] + model2.b) / w[1]\n",
    "    yy4 = - 1 * (xx*w[0] + model2.b - 1) / w[1]\n",
    "    yy5 = - 1 * (xx*w[0] + model2.b + 1) / w[1]\n",
    "    axs[1].plot(xx, yy3, 'k--', label='hyperplan')\n",
    "    axs[1].plot(xx, yy4, 'k-', label='margin')\n",
    "    axs[1].plot(xx, yy5, 'k-', label='margin')\n",
    "    axs[1].scatter(Xall[:, 0], Xall[:, 1], c = yall)\n",
    "    axs[1].set_title('SMO, accuracy: ' + str(acc3), fontsize=16)\n",
    "    axs[1].legend(loc='best', fontsize='large')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compareSVC_SMO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compareSVC_SMO(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
