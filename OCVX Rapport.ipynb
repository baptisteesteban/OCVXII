{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ocvx\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1: Méthode de Newton\n",
    "\n",
    "Avant de commencer à étudier la méthode de Newton, générons des problèmes d'optimisation convexe sans contraintes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unconstrained = ocvx.getUnconstrainedProblems()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode de Newton est une méthode permettant de résoudre des problèmes d'optimisation convexe. Sa principale différence par rapport à la descente de gradient est l'utilisation de la héssienne de la fonction objectif. Cela fait de la méthode de Newton une méthode de second ordre. Son fonctionnement ayant déjà été expliqué en cours, nous ne la décririons pas dans cette partie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(unconstrained.shape[0]):\n",
    "    print(\"Problem\", i, \":\", unconstrained.iloc[i][\"name\"], \"with constant\")\n",
    "    P = unconstrained.iloc[i][\"probleme\"]\n",
    "    if P.f.dim == 1:\n",
    "        x0 = np.array([10])\n",
    "    else:\n",
    "        x0 = np.array([15, 20])\n",
    "    meth = ocvx.Newton(P, ocvx.constant)\n",
    "    print(\"x* =\", meth(x0))\n",
    "    print(\"Nombre d'itération:\", meth.save.shape[0])\n",
    "    meth.plot()\n",
    "    \n",
    "    print(\"Problem\", i, \":\", unconstrained.iloc[i][\"name\"], \"with backtracking\")\n",
    "    meth = ocvx.Newton(P, ocvx.backtracking)\n",
    "    print(\"x* =\", meth(x0))\n",
    "    print(\"Nombre d'itération:\", meth.save.shape[0])\n",
    "    meth.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur les graphiques ci-dessus, les points rouges représentent les points à chaque itération de l'algorithme. Pour les fonction en deux dimensions, nous avons choisi de les représenter sous la forme de lignes de niveau. Plus la couleur de la courbe est sombre, plus la valeur de la fonction objectif est petite.\n",
    "\n",
    "La première observation que l'on peut faire est que la méthode de Newton avec une valeur de pas constant (dans notre cas fixé empiriquement à une valeur de 0.01) est beaucoup plus lente qu'avec une valeur de pas calculée à chaque itération de notre algorithme à l'aide du **backtracking**.\n",
    "\n",
    "Comparons maintenant la descente de gradient (classique) à la méthode de Newton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(unconstrained.shape[0]):\n",
    "    print(\"Problem\", i, \":\", unconstrained.iloc[i][\"name\"], \"with constant\")\n",
    "    P = unconstrained.iloc[i][\"probleme\"]\n",
    "    if P.f.dim == 1:\n",
    "        x0 = np.array([10])\n",
    "    else:\n",
    "        x0 = np.array([15, 20])\n",
    "    meth = ocvx.GradientDescent(P, ocvx.constant)\n",
    "    print(\"x* =\", meth(x0))\n",
    "    print(\"Nombre d'itération:\", meth.save.shape[0])\n",
    "    meth.plot()\n",
    "    \n",
    "    print(\"Problem\", i, \":\", unconstrained.iloc[i][\"name\"], \"with backtracking\")\n",
    "    meth = ocvx.GradientDescent(P, ocvx.backtracking)\n",
    "    print(\"x* =\", meth(x0))\n",
    "    print(\"Nombre d'itération:\", meth.save.shape[0])\n",
    "    meth.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode de Newton et la descente de gradient présente plusieurs différences plusieurs différences. Premièrement, la descente de gradient avec un pas constant prend moins d'itérations pour minimiser la fonction objectif. Cela est surement dû au fait que la descente de gradient est une méthode de premier ordre qui dépend du gradient alors que la méthode de Newton dépend de la Hessienne.\n",
    "\n",
    "Ensuite, on observe que la descente de gradient utilisant le backtracking pour le calcul du pas va parfois trop loin et donc nécéssite de retourner en arrière pour minimiser la fonction objectif. On a donc plus d'itération pour la descente de gradient que pour la méthode de Newton en utilisant le backtracking."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
